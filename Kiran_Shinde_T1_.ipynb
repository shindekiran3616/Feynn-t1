{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e304bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bioinfokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea602fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioinfokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2d20d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from bioinfokit.visuz import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4641d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/hp/Desktop/baclass22/mcdonalds.csv\")\n",
    "data1=pd.read_csv(\"C:/Users/hp/Desktop/baclass22/mcdonalds.csv\")\n",
    "column_names = data.columns.values.tolist()\n",
    "print(column_names)\n",
    "# this command is used for to indicate the list of variables ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96ff002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape \n",
    "# this command is used for how many rows and column in Our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8fa61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5) \n",
    "# To show that first 5 rows that's why we used this data.head command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f3771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first 11 columns of the data DataFrame using iloc and creates a new DataFrame named MD. It replaces \n",
    " #the string values \"Yes\" with the integer value 1 and \"No\" with the integer value 0.\n",
    "    \n",
    "\n",
    "MD=data.iloc[:,0:11].replace(\"Yes\",1).replace(\"No\",0)\n",
    "mean=round(MD.mean(),2)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767e85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA() class is initialized, and then fit_transform() is \n",
    "# used to fit the PCA model to the MD DataFrame and transform the data into the principal components.\n",
    "#np.sqrt(pca.explained_variance_), and the proportion of variance \n",
    "# explained by each component is obtained using pca.explained_variance_ratio_\n",
    "\n",
    "#Finally, a DataFrame named summary is created using pd.DataFrame() with the standard deviation, \n",
    "# proportion of variance, and cumulative proportion as columns, and the index labels from index\n",
    "\n",
    "\n",
    "pca = PCA() \n",
    "MD_pca=pca.fit_transform(MD)\n",
    "MD_p=pca.fit(MD)\n",
    "\n",
    "SD=np.sqrt(pca.explained_variance_)\n",
    "PV=pca.explained_variance_ratio_\n",
    "index=[]\n",
    "for i in range(len(SD)):\n",
    "    i=i+1\n",
    "    index.append(\"PC{}\".format(i))\n",
    "\n",
    "sum=pd.DataFrame({\n",
    "    \"Standard deviation\":SD,\"Proportion of Variance\":PV,\"Cumulative Proportion\":PV.cumsum()\n",
    "},index=index)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528d73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Deviation:\\n\",SD.round(1))  \n",
    "\n",
    "# SD Means it represent the standard deviation of the each principle component .and \n",
    "# round one means values to one decimal place \n",
    "\n",
    "\n",
    "load = (pca.components_) \n",
    "# Loading the variable \n",
    "i=0\n",
    "\n",
    "rot_matrix = MD_p.components_.T \n",
    "\n",
    "#Here, the variable rot_matrix is created to store the rotated principal component loadings. \n",
    "# MD_p is the PCA instance fitted on the original data, without transformation.\n",
    "\n",
    "\n",
    "#The DataFrame is constructed using the pd.DataFrame() function, where rot_matrix represents the data, \n",
    "# MD.columns.values represents the index (original variable names), and index represents the column names (created earlier).\n",
    "\n",
    "rot_df = pd.DataFrame(rot_matrix, index=MD.columns.values, columns=index)\n",
    "\n",
    "# function rounds the values in the rot_df DataFrame to three decimal places. \n",
    "#  Additionally, a negative sign is applied to reverse the direction of the loadings for better interpretation\n",
    "\n",
    "rot_df=round(-rot_df,3)\n",
    "rot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1859cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will assume a standard biplot function is being used that takes the following parameters:\n",
    "#cscore: The principal component scores or transformed data. In this case, it is represented \n",
    "# by MD_pca, which likely contains the transformed data obtained after performing PCA\n",
    "#loadings: The principal component loadings. In the code, it is \n",
    "#represented by -load, where load likely contains the loadings obtained from the PCA\n",
    "#var1 and var2: The indices or labels of the two principal components to be plotted. \n",
    "# In this case, both are set to 0, indicating the first principal component.\n",
    "#show: A boolean value indicating whether to display the biplot. It is set to True in the code\n",
    "# dimension of the size \n",
    "\n",
    "cluster.biplot(cscore=MD_pca, loadings=-load, labels=data.columns.values,var1=0,var2=0, show=True, dim=(10, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcea2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km=KMeans(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1619ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234) \n",
    "#The np.random.seed(1234) line sets the random seed for the NumPy random number generator to 1234\n",
    "\n",
    "nrep = 10 \n",
    "#This variable represents the number of repetitions for the K-means algorithm.\n",
    "\n",
    "num_segments = range(1, 9) \n",
    "\n",
    "#num_segments variable is assigned the range from 1 to 8 using range(1, 9). \n",
    "# This variable will be used to define the different numbers of clusters\n",
    "\n",
    "within_cluster_distances = []\n",
    "#It will store the sum of within-cluster distances for each number of clusters.\n",
    "\n",
    "MD_km28 = {} \n",
    "# It will store the KMeans objects corresponding to each number of clusters.\n",
    "  \n",
    "    \n",
    "    \n",
    "#Creates a K-means clustering object kmeans using KMeans() from scikit-learn's cluster module. \n",
    "#The number of clusters is set to k, the number of initializations is set to nrep, and the random seed is set to 1234.\n",
    "\n",
    "#Fits the K-means model to the data MD using the fit() method.\n",
    " #Appends the sum of within-cluster distances (retrieved using inertia_) to the within_cluster_distances list.\n",
    " #Stores the KMeans object in the MD_km28 dictionary using the number of clusters (k) as the key.\n",
    "for k in num_segments:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=nrep, random_state=1234)\n",
    "    kmeans.fit(MD)\n",
    "    within_cluster_distances.append((kmeans.inertia_))\n",
    "    MD_km28[str(k)] = kmeans\n",
    "\n",
    "    \n",
    "    \n",
    "#This code uses matplotlib's plt.bar() function to create a bar plot.\n",
    "plt.bar(num_segments, within_cluster_distances)\n",
    "plt.xlabel(\"Number of segments\") # x axis of the plot represent the different number of segment \n",
    "plt.ylabel(\"Sum of within-cluster distances\")# y axis of plot represent the sum of within-cluster distances are stored\n",
    "# in the within _cluster_distances\n",
    "plt.title(\"Segmentation Results\")\n",
    "plt.show()\n",
    "#The plot helps visualize the relationship between the number of clusters \n",
    "#and the sum of within-cluster distances, providing insights into the optimal number of clusters for the given data set.\n",
    "#The plot helps visualize the relationship between the number of clusters and the sum of within-cluster distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65e06297",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee88a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "741d8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade bioinfokit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62eabd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234) \n",
    "nboot = 100  \n",
    "nrep = 10 #These lines define the variables nboot and nrep. nboot represents the number of bootstrap samples to generate, \n",
    "# and nrep represents the number of repetitions for the K-means algorithm\n",
    "\n",
    "bootstrap_samples = []\n",
    "for _ in range(nboot): #This loop generates nboot bootstrap samples using the resample() function\n",
    "    bootstrap_sample = resample(MD.values, random_state=1234) \n",
    "    bootstrap_samples.append(bootstrap_sample)\n",
    "\n",
    "    \n",
    "## bootstrap clustering and calculates the adjusted Rand index for each number of segments (k) in the range from 2 to 8 (num_segments).\n",
    "\n",
    "#The outer loop iterates over each k in num_segments.\n",
    "#The stability_scores list is initialized to store the adjusted Rand index values for each bootstrap sample.\n",
    "#The inner loop iterates over each bootstrap sample.\n",
    "#For each bootstrap sample, a K-means clustering model is created using the KMeans() function. \n",
    "#The number of clusters is set to k, the number of repetitions is set to nrep, and the random seed is set to 1234.\n",
    "#The K-means model is fitted to the bootstrap sample using the fit() method.\n",
    "#Cluster labels are obtained using the predict() method on the bootstrap sample.\n",
    "#True labels are obtained by predicting cluster labels on the original data MD.values.\n",
    "#The adjusted Rand index is calculated using the adjusted_rand_score() function, which compares the similarity between true \n",
    "#and predicted labels.\n",
    "#The stability score is appended to the stability_scores list.\n",
    "#The stability_scores list is appended to the adjusted_rand_index list.\n",
    "\n",
    "adjusted_rand_index = []\n",
    "num_segments = range(2, 9)\n",
    "for k in num_segments:\n",
    "    stability_scores = []\n",
    "    for bootstrap_sample in bootstrap_samples:\n",
    "        kmeans = KMeans(n_clusters=k, n_init=nrep, random_state=1234)  \n",
    "        kmeans.fit(bootstrap_sample)\n",
    "        cluster_labels = kmeans.predict(bootstrap_sample)\n",
    "        true_labels = kmeans.predict(MD.values)\n",
    "        stability_score = adjusted_rand_score(true_labels, cluster_labels)\n",
    "        stability_scores.append(stability_score)\n",
    "    adjusted_rand_index.append(stability_scores)\n",
    "\n",
    "# Transpose the adjusted_rand_index list\n",
    "adjusted_rand_index = np.array(adjusted_rand_index).T#This line transposes the adjusted_rand_index list using np.array().T, \n",
    "# so that each row represents a bootstrap sample and each column represents a number of segments (k).\n",
    "\n",
    "# Create boxplot of adjusted Rand index\n",
    "plt.boxplot(adjusted_rand_index, labels=num_segments, whis=10)\n",
    "plt.xlabel(\"Number of segments\")\n",
    "plt.ylabel(\"Adjusted Rand Index\")\n",
    "plt.title(\"Bootstrap Flexclust\")\n",
    "plt.show()\n",
    "#The plt.xlabel(), plt.ylabel(), and plt.title() functions set the labels and title for the plot.\n",
    "#plt.show() displays the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b053d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_values = (0, 1)#Set the range of values for the x-axis (range_values) to be from 0 to 1.\n",
    "\n",
    "num_bins = 10 #Define the number of bins (num_bins) for the histogram.\n",
    "\n",
    "max_frequency = 200 #Specify the maximum frequency (max_frequency) to be displayed on the y-axis\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))#Create a figure and a 2x2 grid of subplots using plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "\n",
    "for i in range(1, 5):#Iterate over each cluster using the loop for i in range(1, 5) \n",
    "    #(clusters are assumed to be numbered from 1 to 4\n",
    "    labels = MD_km28[str(i)].predict(MD)#Predict the labels for the given data (MD) using the \n",
    "    #clustering model MD_km28[str(i)] and assign them to labels\n",
    "    similarities = MD_km28[str(i)].transform(MD).min(axis=1)\n",
    "    row = (i - 1) // 2\n",
    "    col = (i - 1) % 2#Calculate the row and column indices in the subplot grid based on \n",
    "    # the current cluster number (i) using the formulas (i - 1) // 2 and (i - 1) % 2, respectively.\n",
    "\n",
    "    \n",
    "#Plot a histogram of the similarities data using axs[row, col].hist(similarities, bins=num_bins, range=range_values). \n",
    "# This will create a histogram plot\n",
    "\n",
    "\n",
    "    axs[row, col].hist(similarities, bins=num_bins, range=range_values)\n",
    "\n",
    "    axs[row, col].set_xlabel('Similarity')\n",
    "    axs[row, col].set_ylabel('Frequency')\n",
    "    axs[row, col].set_title('cluster {}'.format(i))\n",
    "    axs[row, col].set_xlim(range_values)\n",
    "    axs[row, col].set_ylim(0, max_frequency)\n",
    "\n",
    "#Set the x-axis tick positions to [0, 0.2, 0.4, 0.6, 0.8, 1.0] using axs[row, col].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "    axs[row, col].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c48795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a range of values for the number of segments (num_segments) from 2 to 8.\n",
    "#Create an empty list segment_stability to store the labels for each segment.\n",
    "#Iterate over each segment using the loop for segment in range(2, 9).\n",
    "#Predict the labels for the given data (MD) using the clustering model MD_km28[str(segment)] and assign them to labels_segment. This step calculates the cluster labels for each data point in the dataset using the specified number of segments.\n",
    "#Append the labels_segment to the segment_stability list. This step adds the predicted cluster labels for each segment to the segment_stability list.\n",
    "#Create a new figure with a size of 8x6 using plt.figure(figsize=(8, 6)) to initialize a figure for the plot.\n",
    "\n",
    "num_segments = range(2, 9)\n",
    "\n",
    "segment_stability = []\n",
    "\n",
    "#Iterate over each segment using the loop for segment in range(2, 9).\n",
    "# Iterate over each segment using the loop for segment in range(2, 9).\n",
    "# Predict the labels for the given data (MD) using the clustering model MD_km28[str(segment)] and assign them to labels_segment. \n",
    "#This step calculates the cluster labels for each data point in the dataset using the specified number of segments.\n",
    "#Append the labels_segment to the segment_stability list. This step adds the predicted cluster labels for \n",
    "#each segment to the segment_stability list.\n",
    "for segment in range(2, 9):\n",
    "    labels_segment = MD_km28[str(segment)].predict(MD)\n",
    "    segment_stability.append(labels_segment)\n",
    "\n",
    "#Create a new figure with a size of 8x6 using plt.figure(figsize=(8, 6)) to \n",
    "# initialize a figure for the plotplt.figure(figsize=(8, 6))\n",
    "for i, segment in enumerate(range(2, 9)):\n",
    "    plt.plot(num_segments, [np.mean(segment_stability[i] == labels) for labels in segment_stability], marker='o', label=f'Segment {segment}')\n",
    "\n",
    "#Plot a line graph for each segment, showing the segment level stability, using plt.plot(num_segments, \n",
    "#[np.mean(segment_stability[i] == labels) for labels in segment_stability], marker='o', label=f'Segment {segment}').\n",
    "#num_segments is used as the x-values for the plot, representing the number of segments.\n",
    "#[np.mean(segment_stability[i] == labels) for labels in segment_stability] calculates the segment level stability for each label set in segment_stability. It compares each label set to the labels for the current segment (segment_stability[i]) and calculates the mean, resulting in a stability value.\n",
    "#marker='o' adds circular markers to the plot points for better visibility.\n",
    "#label=f'Segment {segment}' sets the label for the legend based on the segment number.\n",
    "\n",
    "\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Segment Level Stability')\n",
    "plt.title('Segment Level Stability Across Solutions (SLSA) Plot')\n",
    "plt.xticks(num_segments)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "#Display a legend for the different segments using plt.legend().\n",
    "#Add a grid to the plot using plt.grid(True) to improve readability.\n",
    "#Finally, use plt.show() to display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f8b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_solutions = [\"2\", \"3\", \"4\", \"5\"]\n",
    "segment_labels = {}\n",
    "segment_similarities = {}\n",
    "\n",
    "for segment in segment_solutions:\n",
    "    segment_labels[segment] = MD_km28[segment].predict(MD)\n",
    "    segment_similarities[segment] = MD_km28[segment].transform(MD).min(axis=1)\n",
    "\n",
    "segment_stability_values = []\n",
    "for segment in segment_solutions:\n",
    "    similarities = segment_similarities[segment]\n",
    "    normalized_similarities = similarities / np.max(similarities) \n",
    "    segment_stability_values.append(normalized_similarities)\n",
    "\n",
    "plt.boxplot(segment_stability_values, whis=1.5)\n",
    "plt.xlabel(\"Segment Number\")\n",
    "plt.ylabel(\"Segment Stability\")\n",
    "plt.xticks(range(1, len(segment_solutions) + 1), segment_solutions)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Segment Level Stability within Solutions\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "721ec39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a range of values for the number of clusters (k_values) from 2 to 8.\n",
    "#Create an empty list MD_m28 to store the metrics and statistics for each value of k.\n",
    "#Iterate over each value of k using the loop for k in k_values.\n",
    "#Create a KMeans model with the specified number of clusters (k) and a random seed of 1234 using model = KMeans(n_clusters=k, random_state=1234).\n",
    "#Fit the KMeans model to the data (MD.values) using model.fit(MD.values)\n",
    " #Set the converged variable to True since the algorithm has converged.\n",
    "#Assign the values of k to both k_val and k0_val. (It seems k0_val is redundant here, as it has the same value as k.)\n",
    "#Calculate the log-likelihood of the model (-model.inertia_) and assign it to log_likelihood.\n",
    "#Obtain the number of samples (n_samples) and the number of features (_) in the dataset (MD.shape).\n",
    "#Calculate the AIC (Akaike Information Criterion) using the formula -2 * log_likelihood + 2 * k and assign it to aic.\n",
    "#Calculate the probabilities of each cluster label by dividing counts by the sum of all counts using counts / float(counts.sum()) and assign them to probs.\n",
    "#Calculate the entropy of the cluster probabilities using entropy(probs) and assign it to class_entropy.\n",
    "\n",
    "#Append a tuple containing all the calculated metrics and statistics to the MD_m28 list.\n",
    "#Print the resulting DataFrame MD_m28, which displays the calculated metrics and statistics for each value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06c66546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "np.random.seed(1234)\n",
    "k_values = range(2, 9)\n",
    "MD_m28 = []\n",
    "\n",
    "for k in k_values:\n",
    "    model = KMeans(n_clusters=k, random_state=1234)\n",
    "    model.fit(MD.values)\n",
    "    iter_val = model.n_iter_\n",
    "    converged = True\n",
    "    k_val = k\n",
    "    k0_val = k\n",
    "    log_likelihood = -model.inertia_\n",
    "    n_samples, _ = MD.shape\n",
    "    aic = -2 * log_likelihood + 2 * k\n",
    "    bic = -2 * log_likelihood + np.log(n_samples) * k\n",
    "    labels = model.labels_\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / float(counts.sum())\n",
    "    class_entropy = entropy(probs)\n",
    "    icl = bic - class_entropy\n",
    "    \n",
    "    MD_m28.append((iter_val, converged, k_val, k0_val, log_likelihood, aic, bic, icl))\n",
    "MD_m28 = pd.DataFrame(MD_m28, columns=['iter', 'converged', 'k', 'k0', 'logLik', 'AIC', 'BIC', 'ICL'])\n",
    "\n",
    "print(MD_m28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86720299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## With the help of AIC ,BIC ICL Values we are plotting x axis Number of Segments and Value of Information Criteria ,\n",
    "# Information criteria is used as title .\n",
    "\n",
    "\n",
    "num_segments = MD_m28[\"k\"]\n",
    "AIC_values = MD_m28[\"AIC\"]\n",
    "BIC_values = MD_m28[\"BIC\"]\n",
    "ICL_values = MD_m28[\"ICL\"]\n",
    "\n",
    "plt.plot(num_segments, AIC_values, marker='o', label='AIC')\n",
    "plt.plot(num_segments, BIC_values, marker='o', label='BIC')\n",
    "plt.plot(num_segments, ICL_values, marker='o', label='ICL')\n",
    "\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Value of Information Criteria')\n",
    "plt.title('Information Criteria (AIC, BIC, ICL)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64cba50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the number of clusters (k) to 4.\n",
    "#Create a K-means clustering model with the specified number of clusters (k) and a random seed of 1234 using kmeans = KMeans(n_clusters=k, random_state=1234).\n",
    "#Fit the K-means model to the data (MD) using kmeans.fit(MD).\n",
    "#Predict the cluster assignments for the data using kmeans.predict(MD) and assign the results to kmeans_clusters.\n",
    "#Create a GMM model with the specified number of components (k) and a random seed of 1234 using gmm = GaussianMixture(n_components=k, random_state=1234).\n",
    "#Fit the GMM model to the data (MD) using gmm.fit(MD).\n",
    "#Predict the cluster assignments for the data using gmm.predict(MD) and assign the results to gmm_clusters.\n",
    "#Create a DataFrame results that combines the cluster assignments from K-means (kmeans_clusters) and GMM (gmm_clusters).\n",
    "#Create a K-means clustering model (k4_m4) with the specified number of clusters (k) and a random seed of 1234.\n",
    "#Fit the K-means model to the subsetted data (MD_m4) using k4_m4.fit(MD_m4).\n",
    "#Predict the cluster assignments for the subsetted data using k4_m4.predict(MD_m4) and assign the results to k4_m4_clusters.\n",
    "#Create a DataFrame results_m4 that contains the cluster assignments from the K-means clustering on the subsetted data (k4_m4_clusters) and assigns all values as 3 to match the 'mixture' column.\n",
    "#Print the cross-tabulation of the cluster assignments between K-means and GMM using pd.crosstab(results['kmeans'], results['mixture'])\n",
    "#Print the cross-tabulation of the cluster assignments between K-means on the full data and K-means on the subsetted data using pd.crosstab(results['kmeans'], results_m4['kmeans'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0680dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=1234)\n",
    "kmeans.fit(MD)\n",
    "kmeans_clusters = kmeans.predict(MD)\n",
    "\n",
    "gmm = GaussianMixture(n_components=k, random_state=1234)\n",
    "gmm.fit(MD)\n",
    "gmm_clusters = gmm.predict(MD)\n",
    "\n",
    "results = pd.DataFrame({'kmeans': kmeans_clusters, 'mixture': gmm_clusters})\n",
    "\n",
    "MD_m4 = MD[results['mixture'] == 3] \n",
    "\n",
    "k4_m4 = KMeans(n_clusters=k, random_state=1234)\n",
    "k4_m4.fit(MD_m4)\n",
    "k4_m4_clusters = k4_m4.predict(MD_m4)\n",
    "\n",
    "results_m4 = pd.DataFrame({'kmeans': k4_m4_clusters, 'mixture': 3})\n",
    "\n",
    "print(pd.crosstab(results['kmeans'], results['mixture']))\n",
    "print(pd.crosstab(results['kmeans'], results_m4['kmeans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9042a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b976f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set the number of clusters (k) to 4.\n",
    "#Create a K-means clustering model with the specified number of clusters (k) and a random seed of 1234 using kmeans = KMeans(n_clusters=k, random_state=1234).\n",
    "#Fit the K-means model to the data (MD) using kmeans.fit(MD).\n",
    "#Predict the cluster assignments for the data using kmeans.predict(MD) and assign the results to kmeans_clusters.\n",
    "#Create a GMM model with the specified number of components (k) and a random seed of 1234 using gmm = GaussianMixture(n_components=k, random_state=1234).\n",
    " #Fit the GMM model to the data (MD) using gmm.fit(MD).\n",
    "#Predict the cluster assignments for the data using gmm.predict(MD) and assign the results to gmm_clusters\n",
    "#Create a K-means clustering model (k4_m4) with the specified number of clusters (k) and a random seed of 1234.\n",
    "#Fit the K-means model to the subsetted data (MD_m4) using k4_m4.fit(MD_m4).\n",
    "#Predict the cluster assignments for the subsetted data using k4_m4.predict(MD_m4) and assign the results to k4_m4_clusters.\n",
    "#Create a DataFrame results_m4 that contains the cluster assignments from the K-means clustering on the subsetted data (k4_m4_clusters) and assigns all values as 3 to match the 'mixture' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0154cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=1234)\n",
    "kmeans.fit(MD)\n",
    "kmeans_clusters = kmeans.predict(MD)\n",
    "\n",
    "gmm = GaussianMixture(n_components=k, random_state=1234)\n",
    "gmm.fit(MD)\n",
    "gmm_clusters = gmm.predict(MD)\n",
    "\n",
    "results = pd.DataFrame({'kmeans': kmeans_clusters, 'mixture': gmm_clusters})\n",
    "\n",
    "MD_m4 = MD[results['mixture'] == 3] \n",
    "\n",
    "k4_m4 = KMeans(n_clusters=k, random_state=1234)\n",
    "k4_m4.fit(MD_m4)\n",
    "k4_m4_clusters = k4_m4.predict(MD_m4)\n",
    "\n",
    "results_m4 = pd.DataFrame({'kmeans': k4_m4_clusters, 'mixture': 3})\n",
    "\n",
    "print(pd.crosstab(results['kmeans'], results['mixture']))\n",
    "print(pd.crosstab(results['kmeans'], results_m4['kmeans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9ed23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a85e8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set the number of clusters (k) to 4.\n",
    "#Create a K-means clustering model with the specified number of clusters (k) and a random seed of 1234 using kmeans = KMeans(n_clusters=k, random_state=1234).\n",
    "#Fit the K-means model to the data (MD) using kmeans.fit(MD).\n",
    "#Predict the cluster assignments for the data using kmeans.predict(MD) and assign the results to kmeans_clusters.\n",
    "#Create a GMM model with the specified number of components (k) and a random seed of 1234 using gmm = GaussianMixture(n_components=k, random_state=1234).\n",
    " #Fit the GMM model to the data (MD) using gmm.fit(MD).\n",
    "#Predict the cluster assignments for the data using gmm.predict(MD) and assign the results to gmm_clusters\n",
    "#Create a K-means clustering model (k4_m4) with the specified number of clusters (k) and a random seed of 1234.\n",
    "#Fit the K-means model to the subsetted data (MD_m4) using k4_m4.fit(MD_m4).\n",
    "#Predict the cluster assignments for the subsetted data using k4_m4.predict(MD_m4) and assign the results to k4_m4_clusters.\n",
    "#Create a DataFrame results_m4 that contains the cluster assignments from the K-means clustering on the subsetted data (k4_m4_clusters) and assigns all values as 3 to match the 'mixture' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de4e8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "gmm_m4a = GaussianMixture(n_components=4)\n",
    "gmm_m4a.fit(MD)\n",
    "\n",
    "log_likelihood_m4a = gmm_m4a.score(MD)\n",
    "\n",
    "gmm_m4 = GaussianMixture(n_components=4)\n",
    "gmm_m4.fit(MD)\n",
    "\n",
    "log_likelihood_m4 = gmm_m4.score(MD)\n",
    "\n",
    "print(\"Log-likelihood for MD.m4a:\", log_likelihood_m4a)\n",
    "print(\"Log-likelihood for MD.m4:\", log_likelihood_m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "145e812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform value counting on the 'Like' column of the DataFrame data using \n",
    "#pd.value_counts(data['Like']) and assign the result to like_counts\n",
    "#Reverse the order of the value counts by using .iloc[::-1] on like_counts.\n",
    "#Print the reversed value counts using print(reversed_counts).\n",
    "like_counts = pd.value_counts(data['Like'])\n",
    "reversed_counts = like_counts.iloc[::-1]\n",
    "\n",
    "print(reversed_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eda841c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of string values to numeric codes\n",
    "like_mapping = {\n",
    "    'I HATE IT!-5': -5,\n",
    "    '-4': -4,\n",
    "    '-3': -3,\n",
    "    '-2': -2,\n",
    "    '-1': -1,\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    'I LOVE IT!+5': 5\n",
    "}\n",
    "\n",
    "data['Like.n'] = data['Like'].map(like_mapping)\n",
    "\n",
    "\n",
    "like_n_counts = data['Like.n'].value_counts()\n",
    "\n",
    "\n",
    "print(like_n_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28c6f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "\n",
    "independent_vars = data.columns[0:11] \n",
    "\n",
    "formula_str = ' + '.join(independent_vars)\n",
    "\n",
    "formula_str = 'Like ~ ' + formula_str\n",
    "\n",
    "\n",
    "f = dmatrices(formula_str, data=data)[1]\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "934b06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from patsy import dmatrix\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = dmatrix(f.design_info, data=data)\n",
    "y = dmatrix('Like', data=data)\n",
    "\n",
    "n_components = 2\n",
    "n_init = 10\n",
    "verbose = False\n",
    "n_rep=10\n",
    "\n",
    "model = GaussianMixture(n_components=n_components, n_init=n_init, verbose=verbose)\n",
    "MD_reg2 = model.fit(X, y)\n",
    "\n",
    "print(MD_reg2)\n",
    "cluster_sizes = np.bincount(model.predict(X))\n",
    "\n",
    "print(\"Cluster sizes:\")\n",
    "for i, size in enumerate(cluster_sizes):\n",
    "    print(f\"{i+1}: {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbbf0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we have to find component of 1,2,3,4 with the help of the matplotlib library using this suitable library we will get the plot\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans = MD_km28['4']\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "MD_mean = MD.groupby(labels).mean()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axs[0, 0].barh(range(MD_mean.shape[1]), MD_mean.iloc[0])\n",
    "axs[0, 0].set_title('Component 1')\n",
    "axs[0, 1].barh(range(MD_mean.shape[1]), MD_mean.iloc[1])\n",
    "axs[0, 1].set_title('Component 2')\n",
    "axs[1, 0].barh(range(MD_mean.shape[1]), MD_mean.iloc[2])\n",
    "axs[1, 0].set_title('Component 3')\n",
    "axs[1, 1].barh(range(MD_mean.shape[1]), MD_mean.iloc[3])\n",
    "axs[1, 1].set_title('Component 4')\n",
    "\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(ylabel='Variable', xlabel='Proportion')\n",
    "    ax.set_yticks(range(MD_mean.shape[1]))\n",
    "    ax.set_yticklabels(MD.columns)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.suptitle('Segment Profiles')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42ffc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(MD)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "MD_pca = pca.fit_transform(MD)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(MD_pca[:, 0], MD_pca[:, 1])\n",
    "ax.set_xlabel('principal component 1')\n",
    "ax.set_ylabel('principal component 2')\n",
    "plt.show()\n",
    "\n",
    "# here we can see first we have plot of pca 1 vs pca2 . then here we can see that here there are three cluster of the given datasets .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "935c1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from itertools import product\n",
    "#Label encoding for categorical - Converting 11 cols with yes/no\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def labelling(x):\n",
    "    data1[x] = LabelEncoder().fit_transform(data1[x])\n",
    "    return data1\n",
    "\n",
    "cat = ['yummy', 'convenient', 'spicy', 'fattening', 'greasy', 'fast', 'cheap',\n",
    "       'tasty', 'expensive', 'healthy', 'disgusting']\n",
    "\n",
    "for i in cat:\n",
    "    labelling(i)\n",
    "data1\n",
    "df_eleven = data1.loc[:,cat]\n",
    "df_eleven\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(df_eleven)\n",
    "data1['cluster_num'] = kmeans.labels_ \n",
    "crosstab =pd.crosstab(data1['cluster_num'],data1['Like'])\n",
    "#Reordering cols\n",
    "data1\n",
    "crosstab = crosstab[['I hate it!-5','-4','-3','-2','-1','0','1','2','3','4','I love it!+5']]\n",
    "crosstab \n",
    "plt.rcParams['figure.figsize'] = (7,5)\n",
    "mosaic(crosstab.stack())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ee2674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Retrieve the cluster assignments for the specific cluster solution with 4 clusters (MD_km28['4']) and assign them to MD_k4.\n",
    "#Extract the labels from MD_k4 using MD_k4.labels_ and assign them to k4.\n",
    "#Perform cross-tabulation between k4 (cluster assignments) and data['Gender'] using pd.crosstab(k4, data['Gender']) and \n",
    "#assign the result to ct. This step creates a contingency table that counts the occurrences of each combination of cluster \n",
    "#assignments and gender.\n",
    "#Display the contingency table ct.\n",
    "#Create a mosaic plot using mosaic(ct.stack(), gap=0.01). \n",
    "#The mosaic() function accepts the stacked contingency table (ct.stack()) as input and sets the gap between tiles to 0.01.\n",
    "\n",
    "\n",
    "MD_k4=MD_km28['4']\n",
    "k4 = MD_k4.labels_\n",
    "\n",
    "ct = pd.crosstab(k4, data['Gender'])\n",
    "ct\n",
    "mosaic(ct.stack(),gap=0.01)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fda2826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Segment': k4, 'Age': data['Age']})\n",
    "\n",
    "df.boxplot(by='Segment', column='Age')\n",
    "plt.title('Parallel box-and-whisker plot of age by segment')\n",
    "plt.suptitle('')\n",
    "plt.show()\n",
    "## here we plot the box  whiskar . in box whisker we see the middle line of the box whisker .it indicates that 50 percentage \n",
    "# of data . if In Box whisker there upper end and lower end.if the middle line is in upper end so the given data is negatively \n",
    "# skewed .and if middleline is in lower case so the given data is positively skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d30fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['VisitFrequency'] = LabelEncoder().fit_transform(data1['VisitFrequency'])\n",
    "visit = data1.groupby('cluster_num')['VisitFrequency'].mean()\n",
    "visit = visit.to_frame().reset_index()\n",
    "visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b232e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like\n",
    "data1['Like'] = LabelEncoder().fit_transform(data1['Like'])\n",
    "Like = data1.groupby('cluster_num')['Like'].mean()\n",
    "Like = Like.to_frame().reset_index()\n",
    "Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51f79697",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Gender'] = LabelEncoder().fit_transform(data1['Gender'])\n",
    "Gender = data1.groupby('cluster_num')['Gender'].mean()\n",
    "Gender = Gender.to_frame().reset_index()\n",
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5abd6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "segment = Gender.merge(Like, on='cluster_num', how='left').merge(visit, on='cluster_num', how='left')\n",
    "segment\n",
    "plt.figure(figsize = (9,4))\n",
    "sns.scatterplot(x = \"VisitFrequency\", y = \"Like\",data=segment,s=400, color=\"r\")\n",
    "plt.title(\"Simple segment evaluation plot for the fast food data set\",fontsize = 15) \n",
    "plt.xlabel(\"Visit\", fontsize = 12) \n",
    "plt.ylabel(\"Like\", fontsize = 12) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9dfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
